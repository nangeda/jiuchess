#!/usr/bin/env python3
"""
æ•°æ®å¢å¼ºè„šæœ¬ - é€šè¿‡æ£‹ç›˜å¯¹ç§°å˜æ¢æ‰©å……è®­ç»ƒæ•°æ®8å€

ä¹…æ£‹æ£‹ç›˜å…·æœ‰8ç§å¯¹ç§°æ€§ï¼ˆ4ç§æ—‹è½¬ Ã— 2ç§ç¿»è½¬ï¼‰ï¼Œ
åˆ©ç”¨è¿™äº›å¯¹ç§°æ€§å¯ä»¥å¤§å¹…æ‰©å……è®­ç»ƒæ•°æ®ã€‚

ç”¨æ³•ï¼š
    python scripts/augment_dataset.py
    python scripts/augment_dataset.py --input data/processed/train.pt --output data/processed/train_aug.pt
"""
import os
import sys
import argparse
import numpy as np
import torch
from tqdm import tqdm
from copy import deepcopy

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))


def transform_obs(obs: np.ndarray, aug_id: int) -> np.ndarray:
    """
    å¯¹è§‚å¯Ÿè¿›è¡Œå¯¹ç§°å˜æ¢
    
    Args:
        obs: (C, H, W) è§‚å¯Ÿå¼ é‡
        aug_id: 0-7 å˜æ¢ID
            0: åŸå§‹
            1: æ—‹è½¬90åº¦
            2: æ—‹è½¬180åº¦
            3: æ—‹è½¬270åº¦
            4: æ°´å¹³ç¿»è½¬
            5: æ°´å¹³ç¿»è½¬ + æ—‹è½¬90åº¦
            6: æ°´å¹³ç¿»è½¬ + æ—‹è½¬180åº¦
            7: æ°´å¹³ç¿»è½¬ + æ—‹è½¬270åº¦
    
    Returns:
        å˜æ¢åçš„è§‚å¯Ÿ
    """
    if aug_id == 0:
        return obs.copy()
    
    if aug_id < 4:
        # æ—‹è½¬
        return np.rot90(obs, k=aug_id, axes=(1, 2)).copy()
    else:
        # å…ˆç¿»è½¬ï¼Œå†æ—‹è½¬
        obs_flip = np.flip(obs, axis=2).copy()
        k = aug_id - 4
        if k == 0:
            return obs_flip
        return np.rot90(obs_flip, k=k, axes=(1, 2)).copy()


def transform_point(row: int, col: int, aug_id: int, board_size: int = 14) -> tuple:
    """
    å¯¹åæ ‡è¿›è¡Œå¯¹ç§°å˜æ¢
    
    Args:
        row, col: åŸå§‹åæ ‡ (1-indexed)
        aug_id: å˜æ¢ID
        board_size: æ£‹ç›˜å¤§å°
    
    Returns:
        å˜æ¢åçš„ (row, col)
    """
    # è½¬ä¸º0-indexed
    r, c = row - 1, col - 1
    n = board_size
    
    if aug_id == 0:
        new_r, new_c = r, c
    elif aug_id == 1:  # æ—‹è½¬90åº¦
        new_r, new_c = c, n - 1 - r
    elif aug_id == 2:  # æ—‹è½¬180åº¦
        new_r, new_c = n - 1 - r, n - 1 - c
    elif aug_id == 3:  # æ—‹è½¬270åº¦
        new_r, new_c = n - 1 - c, r
    elif aug_id == 4:  # æ°´å¹³ç¿»è½¬
        new_r, new_c = r, n - 1 - c
    elif aug_id == 5:  # æ°´å¹³ç¿»è½¬ + æ—‹è½¬90åº¦
        new_r, new_c = n - 1 - c, n - 1 - r
    elif aug_id == 6:  # æ°´å¹³ç¿»è½¬ + æ—‹è½¬180åº¦
        new_r, new_c = n - 1 - r, c
    elif aug_id == 7:  # æ°´å¹³ç¿»è½¬ + æ—‹è½¬270åº¦
        new_r, new_c = c, r
    else:
        new_r, new_c = r, c
    
    # è½¬å›1-indexed
    return new_r + 1, new_c + 1


def transform_cand_feats(cand_feats: np.ndarray, aug_id: int, board_size: int = 14) -> np.ndarray:
    """
    å¯¹å€™é€‰ç‰¹å¾è¿›è¡Œå¯¹ç§°å˜æ¢
    
    å€™é€‰ç‰¹å¾æ ¼å¼ï¼ˆ14ç»´ï¼‰ï¼š
    - 0-4: act_onehot (5ç»´)
    - 5-6: fromåæ ‡ (2ç»´, å½’ä¸€åŒ–)
    - 7-8: toåæ ‡ (2ç»´, å½’ä¸€åŒ–)
    - 9-10: delta (2ç»´)
    - 11: seq_len
    - 12: phase
    - 13: flying
    """
    if aug_id == 0:
        return cand_feats.copy()
    
    new_feats = cand_feats.copy()
    n = board_size
    
    for i in range(len(new_feats)):
        feat = new_feats[i]
        
        # å˜æ¢fromåæ ‡ (ç´¢å¼•5-6, å€¼åœ¨0-1èŒƒå›´)
        from_r = feat[5] * (n - 1) + 1
        from_c = feat[6] * (n - 1) + 1
        new_from_r, new_from_c = transform_point(from_r, from_c, aug_id, n)
        feat[5] = (new_from_r - 1) / (n - 1)
        feat[6] = (new_from_c - 1) / (n - 1)
        
        # å˜æ¢toåæ ‡ (ç´¢å¼•7-8)
        to_r = feat[7] * (n - 1) + 1
        to_c = feat[8] * (n - 1) + 1
        new_to_r, new_to_c = transform_point(to_r, to_c, aug_id, n)
        feat[7] = (new_to_r - 1) / (n - 1)
        feat[8] = (new_to_c - 1) / (n - 1)
        
        # é‡æ–°è®¡ç®—delta (ç´¢å¼•9-10)
        feat[9] = feat[7] - feat[5]  # delta_r
        feat[10] = feat[8] - feat[6]  # delta_c
    
    return new_feats


def augment_sample(sample: dict, aug_id: int) -> dict:
    """
    å¯¹å•ä¸ªæ ·æœ¬è¿›è¡Œå¢å¼º
    
    Args:
        sample: åŒ…å« obs, phase_id, cand_feats, label_idx, value çš„å­—å…¸
        aug_id: å˜æ¢ID (0-7)
    
    Returns:
        å¢å¼ºåçš„æ ·æœ¬
    """
    if aug_id == 0:
        return deepcopy(sample)
    
    new_sample = {}
    
    # å˜æ¢è§‚å¯Ÿ
    obs = sample['obs']
    if isinstance(obs, torch.Tensor):
        obs = obs.numpy()
    new_sample['obs'] = transform_obs(obs, aug_id)
    
    # ä¿æŒä¸å˜çš„å­—æ®µ
    new_sample['phase_id'] = sample['phase_id']
    new_sample['label_idx'] = sample['label_idx']  # ç´¢å¼•ä¸å˜
    new_sample['value'] = sample['value']
    
    # å˜æ¢å€™é€‰ç‰¹å¾
    cand_feats = sample['cand_feats']
    if isinstance(cand_feats, torch.Tensor):
        cand_feats = cand_feats.numpy()
    new_sample['cand_feats'] = transform_cand_feats(cand_feats, aug_id)
    
    return new_sample


def augment_dataset(
    input_path: str,
    output_path: str,
    num_augmentations: int = 8,
    include_original: bool = True
):
    """
    å¢å¼ºæ•´ä¸ªæ•°æ®é›†
    
    Args:
        input_path: è¾“å…¥.ptæ–‡ä»¶è·¯å¾„
        output_path: è¾“å‡º.ptæ–‡ä»¶è·¯å¾„
        num_augmentations: å¢å¼ºæ•°é‡ (1-8)
        include_original: æ˜¯å¦åŒ…å«åŸå§‹æ ·æœ¬
    """
    print(f"ğŸ“‚ åŠ è½½æ•°æ®: {input_path}")
    data = torch.load(input_path, weights_only=False)
    print(f"   åŸå§‹æ ·æœ¬æ•°: {len(data)}")
    
    augmented_data = []
    
    # ç¡®å®šè¦ä½¿ç”¨çš„å˜æ¢
    aug_ids = list(range(num_augmentations))
    if not include_original and 0 in aug_ids:
        aug_ids = aug_ids[1:]
    
    print(f"ğŸ”„ ä½¿ç”¨ {len(aug_ids)} ç§å˜æ¢: {aug_ids}")
    
    for sample in tqdm(data, desc="å¢å¼ºä¸­"):
        for aug_id in aug_ids:
            try:
                aug_sample = augment_sample(sample, aug_id)
                augmented_data.append(aug_sample)
            except Exception as e:
                print(f"âš ï¸ å¢å¼ºå¤±è´¥ (aug_id={aug_id}): {e}")
                continue
    
    print(f"\nğŸ“Š å¢å¼ºç»“æœ:")
    print(f"   åŸå§‹: {len(data)}")
    print(f"   å¢å¼ºå: {len(augmented_data)}")
    print(f"   å€æ•°: {len(augmented_data) / len(data):.1f}x")
    
    print(f"\nğŸ’¾ ä¿å­˜åˆ°: {output_path}")
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    torch.save(augmented_data, output_path)
    
    # éªŒè¯
    print("\nâœ… éªŒè¯å¢å¼ºæ•°æ®...")
    loaded = torch.load(output_path, weights_only=False)
    print(f"   åŠ è½½æ ·æœ¬æ•°: {len(loaded)}")
    
    # æ£€æŸ¥ç¬¬ä¸€ä¸ªæ ·æœ¬
    sample = loaded[0]
    print(f"   æ ·æœ¬keys: {list(sample.keys())}")
    print(f"   obs shape: {np.array(sample['obs']).shape}")
    print(f"   cand_feats shape: {np.array(sample['cand_feats']).shape}")
    
    print("\nğŸ‰ æ•°æ®å¢å¼ºå®Œæˆ!")


def main():
    parser = argparse.ArgumentParser(description='æ•°æ®å¢å¼ºè„šæœ¬')
    parser.add_argument('--input', type=str, default='data/processed/train.pt',
                        help='è¾“å…¥æ•°æ®é›†è·¯å¾„')
    parser.add_argument('--output', type=str, default='data/processed/train_aug8x.pt',
                        help='è¾“å‡ºæ•°æ®é›†è·¯å¾„')
    parser.add_argument('--num_aug', type=int, default=8,
                        help='å¢å¼ºæ•°é‡ (1-8)')
    parser.add_argument('--no_original', action='store_true',
                        help='ä¸åŒ…å«åŸå§‹æ ·æœ¬ï¼ˆä»…å¢å¼ºï¼‰')
    args = parser.parse_args()
    
    print("="*60)
    print("ğŸ”„ ä¹…æ£‹æ•°æ®å¢å¼ºå·¥å…·")
    print("="*60)
    print(f"è¾“å…¥: {args.input}")
    print(f"è¾“å‡º: {args.output}")
    print(f"å¢å¼ºå€æ•°: {args.num_aug}x")
    print("="*60)
    
    if not os.path.exists(args.input):
        print(f"âŒ é”™è¯¯: è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input}")
        return
    
    augment_dataset(
        input_path=args.input,
        output_path=args.output,
        num_augmentations=args.num_aug,
        include_original=not args.no_original
    )


if __name__ == '__main__':
    main()

